{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Machine Learning Model\n",
    "#### Created by Randhir and Andrew\n",
    "\n",
    "Model that will take a $90\\times120$ thumbnail JPEG and title from YouTube to output a video performance metric.\n",
    "The metric will be \n",
    "$$Score=\\log{(View\\ Count + 1)}$$\n",
    "The idea is that the video that attracted more views is a good video. The value is log-scaled as the higher the view count, the less meaningful it becomes. This value will be normalized with the maximum value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, re, os, json, random\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, TextVectorization, Embedding, Dropout, Concatenate, Input\n",
    "from keras import Model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datagen import ThumbnailDataGenerator\n",
    "\n",
    "# Load .env file with your api key\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "This cell contains the constants used by this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# File Structure\n",
    "dirpath = \"thumbnail\"\n",
    "modeldir = \"models\"\n",
    "datafile = \"data-filtered.csv\"\n",
    "\n",
    "# Data Aquisition\n",
    "filepath = \"data.csv\"\n",
    "count = 50\n",
    "max_iterations = 100 # 50 * 100 = 5000 videos\n",
    "topic_id = \"/m/03hf_rm\" # Strategy Games\n",
    "lang = \"en\"\n",
    "API_KEY = os.getenv(\"APIKEY\")\n",
    "\n",
    "# Regex Patterns\n",
    "emoji_re = \"[\\U000000A9-\\U0010ffff]\"\n",
    "punc_re = f\"[{re.escape(string.punctuation)}]\"\n",
    "\n",
    "# Download Stopwords & pattern\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "sw_re = f'(?:{\"|\".join([f\"{re.escape(sw)}\" for sw in stopwords_list])})'\n",
    "\n",
    "# Text Model Settings\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "# KFold Settings\n",
    "n_folds = 5\n",
    "epochs = 1000\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Aquisition\n",
    "The YouTube API is used to get video data. This includes a video's thumbnail and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data file already exist\n",
    "if os.path.isfile(filepath):\n",
    "    df = pd.read_csv(filepath, index_col=\"yt-id\")\n",
    "else:\n",
    "    df = pd.DataFrame([], columns=[\"yt-id\", \"title\", \"created\", \"channel-id\", \"thumbnail\", \"thumbnail-w\", \"thumbnail-h\", \"view-count\", \"like-count\", \"comment-count\", \"query\"])\n",
    "    df = df.set_index(\"yt-id\")\n",
    "    \n",
    "# Grab missing data IDs for query\n",
    "yt_ids = list(df[df[\"view-count\"].isna()].index)\n",
    "\n",
    "# Loop\n",
    "yt_reads = 0\n",
    "for i in range(max_iterations):\n",
    "    try:\n",
    "        # Check if any stats calls are needed\n",
    "        if len(yt_ids) > 0:\n",
    "            # Message \n",
    "            print(\"Pulling statistics for missing data values\")\n",
    "\n",
    "            # Split up batch by 50 if needed\n",
    "            for index_split in range(50, len(yt_ids) + 1, 50):\n",
    "                # Generate & call statistic query (1 unit)\n",
    "                urlData_stats = f\"https://www.googleapis.com/youtube/v3/videos?key={API_KEY}&part=statistics&id={','.join(yt_ids[index_split - 50:index_split])}\"\n",
    "                webURL_stats = urllib.request.urlopen(urlData_stats)\n",
    "                raw_stats_data = webURL_stats.read()\n",
    "                results_stats = json.loads(raw_stats_data.decode(webURL_stats.info().get_content_charset('utf-8')))\n",
    "\n",
    "                # Process Stats Response\n",
    "                for stats_data in results_stats[\"items\"]:\n",
    "                    try:\n",
    "                        # Parse data\n",
    "                        new_row = pd.DataFrame([{\n",
    "                            \"yt-id\": stats_data['id'],\n",
    "                            \"view-count\": stats_data['statistics']['viewCount'],\n",
    "                            \"like-count\": stats_data['statistics']['likeCount'] if 'likeCount' in stats_data['statistics'] else \"\",\n",
    "                            \"comment-count\": stats_data['statistics']['commentCount'] if 'commentCount' in stats_data['statistics'] else \"\",\n",
    "                        },])\n",
    "                        new_row = new_row.set_index(\"yt-id\")\n",
    "\n",
    "                        # Update main dataset\n",
    "                        df.update(new_row)\n",
    "                    except KeyError:\n",
    "                        # Weird Entry\n",
    "                        continue\n",
    "\n",
    "            # Reset after used\n",
    "            yt_ids = [] \n",
    "\n",
    "            # Message \n",
    "            print(\"Finished pulling statistics for current batch\")\n",
    "\n",
    "        # Message\n",
    "        print(f\"Pulling {count} random videos\")\n",
    "\n",
    "        # Generates random query for YT\n",
    "        r_q = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(3))\n",
    "\n",
    "        # Calls the API for search results (100 units)\n",
    "        urlData_query = f\"https://www.googleapis.com/youtube/v3/search?key={API_KEY}&maxResults={count}&part=snippet&type=video&relevanceLanguage={lang}&topicId={topic_id}&q={r_q}\"\n",
    "        webURL_query = urllib.request.urlopen(urlData_query)\n",
    "        raw_vid_data = webURL_query.read()\n",
    "        results_vids = json.loads(raw_vid_data.decode(webURL_query.info().get_content_charset('utf-8')))\n",
    "\n",
    "        # Process Video Response\n",
    "        for video_data in results_vids['items']:\n",
    "            # Ignore Live and Upcoming Content (no ratings yet)\n",
    "            if video_data['snippet']['liveBroadcastContent'] != \"none\":\n",
    "                continue\n",
    "\n",
    "            # Parse data\n",
    "            try:\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"yt-id\": video_data['id']['videoId'],\n",
    "                    \"title\": video_data['snippet']['title'],\n",
    "                    \"created\": video_data['snippet']['publishedAt'],\n",
    "                    \"channel-id\": video_data['snippet']['channelId'],\n",
    "                    \"thumbnail\": video_data['snippet']['thumbnails'][\"default\"][\"url\"],\n",
    "                    \"thumbnail-w\": video_data['snippet']['thumbnails'][\"default\"][\"width\"],\n",
    "                    \"thumbnail-h\": video_data['snippet']['thumbnails'][\"default\"][\"height\"],\n",
    "                    \"query\": r_q,\n",
    "                },])\n",
    "                new_row = new_row.set_index(\"yt-id\")\n",
    "\n",
    "                try:\n",
    "                    # Append\n",
    "                    df = pd.concat([df, new_row], verify_integrity=True)\n",
    "\n",
    "                    # Store your ids\n",
    "                    yt_reads += 1\n",
    "\n",
    "                    # Prepare id for stats query\n",
    "                    yt_ids.append(video_data['id']['videoId'])\n",
    "                except ValueError:\n",
    "                    # Duplicate video detected\n",
    "                    continue\n",
    "            except KeyError:\n",
    "                # Weird Entry\n",
    "                continue\n",
    "\n",
    "        # Update User\n",
    "        print(f\"API call #{i + 1} successfully\")\n",
    "\n",
    "        # Dumb Data to prevent loss every 5 runs\n",
    "        if i % 5 == 0:\n",
    "            df.to_csv(filepath)\n",
    "\n",
    "    # ON API failure, quit and save\n",
    "    except urllib.error.HTTPError:\n",
    "        print(\"Latest API call failed. You are likely out of units. Try again tomorrow.\")\n",
    "        break\n",
    "    \n",
    "# Write to csv\n",
    "df.to_csv(filepath)\n",
    "\n",
    "# Termination\n",
    "print(f\"Was able to pull {yt_reads} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n",
    "This process involves text processing and image processing. This will involve text standardization and vectorization. For the image, it needs to be processed and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumbnail-w</th>\n",
       "      <th>thumbnail-h</th>\n",
       "      <th>view-count</th>\n",
       "      <th>like-count</th>\n",
       "      <th>comment-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35757.0</td>\n",
       "      <td>35757.0</td>\n",
       "      <td>3.529900e+04</td>\n",
       "      <td>3.431000e+04</td>\n",
       "      <td>35026.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.281597e+04</td>\n",
       "      <td>2.302683e+03</td>\n",
       "      <td>115.941187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.687363e+06</td>\n",
       "      <td>3.116437e+04</td>\n",
       "      <td>1640.474869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.820000e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.154500e+03</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.232996e+08</td>\n",
       "      <td>2.686147e+06</td>\n",
       "      <td>146332.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       thumbnail-w  thumbnail-h    view-count    like-count  comment-count\n",
       "count      35757.0      35757.0  3.529900e+04  3.431000e+04   35026.000000\n",
       "mean         120.0         90.0  9.281597e+04  2.302683e+03     115.941187\n",
       "std            0.0          0.0  1.687363e+06  3.116437e+04    1640.474869\n",
       "min          120.0         90.0  0.000000e+00  0.000000e+00       0.000000\n",
       "25%          120.0         90.0  3.000000e+01  1.000000e+00       0.000000\n",
       "50%          120.0         90.0  2.820000e+02  8.000000e+00       1.000000\n",
       "75%          120.0         90.0  3.154500e+03  7.500000e+01      12.000000\n",
       "max          120.0         90.0  2.232996e+08  2.686147e+06  146332.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(datafile, index_col=\"yt-id\")\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "def text_standardization(raw_strs):\n",
    "\tlower = tf.strings.lower(raw_strs)\n",
    "\temojiless = tf.strings.regex_replace(lower, emoji_re, \"\")\n",
    "\tstopwrdless = tf.strings.regex_replace(emojiless, sw_re, \"\")\n",
    "\tpunctuationless = tf.strings.regex_replace(stopwrdless, punc_re, \"\")\n",
    "\treturn punctuationless\n",
    "\n",
    "# Vectorization Layer\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=text_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02v-CVttnS0.jpg deleted\n",
      "0EZUP5Vtemw.jpg deleted\n",
      "4KlB4i4dEWU.jpg deleted\n",
      "6JhUQpe-J6U.jpg deleted\n",
      "bAHQy0QFUMI.jpg deleted\n",
      "DcejDtVA4MU.jpg deleted\n",
      "E0Hchyxwr4c.jpg deleted\n",
      "ffLdLgSbpEc.jpg deleted\n",
      "hstJLLvhYSM.jpg deleted\n",
      "htE2M7shdfI.jpg deleted\n",
      "JTwsU2dDpEg.jpg deleted\n",
      "Lpnw6hMIu24.jpg deleted\n",
      "Q9D-aQzRuU4.jpg deleted\n",
      "RPoQZ_926hQ.jpg deleted\n",
      "Sl2ueV8kRRU.jpg deleted\n",
      "StkNJFSGksg.jpg deleted\n",
      "tnAYVF1-q74.jpg deleted\n",
      "VDg_U-n3t-I.jpg deleted\n",
      "X82cgnMGeD8.jpg deleted\n",
      "XO6KolPTH8U.jpg deleted\n",
      "XY6Iw4kTOEI.jpg deleted\n",
      "yQKNzY4HGGg.jpg deleted\n",
      "ZBbw3WfcxN8.jpg deleted\n"
     ]
    }
   ],
   "source": [
    "# Filter Images\n",
    "files = [f for f in os.listdir(dirpath) if os.path.isfile(f\"{dirpath}/{f}\") and f.endswith(\".jpg\")]\n",
    "image_ids = []\n",
    "i = 0\n",
    "for f in files:\n",
    "\tim = None\n",
    "\ttry:\n",
    "\t\tim = Image.open(f\"{dirpath}/{f}\")\n",
    "\n",
    "\t\tif im.size != (120, 90):\n",
    "\t\t\tim.close()\n",
    "\t\t\tPath.unlink(f\"{dirpath}/{f}\")\n",
    "\t\t\tprint(f\"{f} deleted\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tim.close()\n",
    "\t\tim = None\n",
    "\n",
    "\t\t# Save valid indexes for filtering\n",
    "\t\timage_ids.append(f[:-4])\n",
    "\texcept:\n",
    "\t\t# Close bad files\n",
    "\t\tif im is not None:\n",
    "\t\t\tim.close()\n",
    "\t\t\tim = None\n",
    "\n",
    "\t\t# Delete Bad Files\n",
    "\t\tPath.unlink(f\"{dirpath}/{f}\")\n",
    "\t\tprint(f\"{f} deleted\")\n",
    "\n",
    "\ti += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Processing\n",
    "files = [f for f in os.listdir(dirpath) if os.path.isfile(f\"{dirpath}/{f}\") and f.endswith(\".jpg\")]\n",
    "images = np.zeros((len(files), 90, 120, 3))\n",
    "image_ids = []\n",
    "valid_index = []\n",
    "i = 0\n",
    "for f in files:\n",
    "\ttry:\n",
    "\t\tim = Image.open(f\"{dirpath}/{f}\")\n",
    "\t\timages[i] = np.array(im)\n",
    "\t\timage_ids.append(f[:-4])\n",
    "\t\tim.close()\n",
    "\n",
    "\t\t# Save valid indexes for filtering\n",
    "\t\tvalid_index.append(i)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\ti += 1\n",
    "\n",
    "# Filter\n",
    "images = images[valid_index]\n",
    "\n",
    "# Normalize Pixels\n",
    "images /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35734.000000\n",
       "mean         0.306272\n",
       "std          0.172596\n",
       "min          0.000000\n",
       "25%          0.173335\n",
       "50%          0.290248\n",
       "75%          0.416793\n",
       "max          1.000000\n",
       "Name: view-count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_with_pic = [f[:-4] for f in os.listdir(dirpath) if os.path.isfile(f\"{dirpath}/{f}\") and f.endswith(\".jpg\")]\n",
    "raw_data = raw_data.loc[ids_with_pic]\n",
    "\n",
    "# Label Processing\n",
    "scores = raw_data[\"view-count\"] # Grab View Count\n",
    "scores = scores.fillna(0.0) # Replace NaN with 0\n",
    "scores = scores.map(lambda x : np.log10(x + 1)) # Log everything to make it less extreme\n",
    "scores = scores.div(scores.max()) # Normalized\n",
    "\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116\n",
      "(32, 90, 120, 3)\n",
      "0.6196078431372549\n"
     ]
    }
   ],
   "source": [
    "tbdg = ThumbnailDataGenerator(dirpath, ids_with_pic, scores)\n",
    "x, y = tbdg[0]\n",
    "\n",
    "print(len(tbdg))\n",
    "print(x.shape)\n",
    "print(x[1,34,113,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, the Sequential API is used to train a model. However, due to the need for more than one input, the Functional API must be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"img_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 120, 3)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 88, 118, 16)       448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 44, 59, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 57, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 21, 28, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 26, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 13, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7488)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               748900    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 772585 (2.95 MB)\n",
      "Trainable params: 772585 (2.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Image Portion\n",
    "img_input = Input((90, 120, 3))\n",
    "x = Conv2D(16, 3, activation='relu', kernel_initializer='he_uniform')(img_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, 3, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "img_output = Dense(1, activation='softmax')(x)\n",
    "\n",
    "img_model = Model(inputs=img_input, outputs=img_output, name=\"img_model\")\n",
    "\n",
    "img_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1, 128)            2560000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 128)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2573001 (9.82 MB)\n",
      "Trainable params: 2573001 (9.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Text Portion\n",
    "text_input = Input((1,), dtype=tf.string)\n",
    "y = Embedding(max_features, embedding_dim)(text_input)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(100, activation='relu', kernel_initializer='he_uniform')(y)\n",
    "text_output = Dense(1, activation='softmax')(y)\n",
    "\n",
    "text_model = Model(inputs=text_input, outputs=text_output, name=\"text_model\")\n",
    "\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unitied_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 120, 3)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 88, 118, 16)          448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 44, 59, 16)           0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 42, 57, 32)           4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 21, 28, 32)           0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 19, 26, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 1, 128)               2560000   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 13, 64)            0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1, 128)               0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 7488)                 0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 128)                  0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100)                  748900    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 100)                  12900     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 200)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 10)                   2010      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    11        ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3347405 (12.77 MB)\n",
      "Trainable params: 3347405 (12.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# United Model\n",
    "z = Concatenate()([x, y])\n",
    "z = Dense(10, activation='relu', kernel_initializer='he_uniform')(z)\n",
    "z = Dense(1, activation='softmax')(z)\n",
    "\n",
    "united_model = Model(inputs=[img_input, text_input], outputs=z, name=\"unitied_model\")\n",
    "\n",
    "united_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Using k-fold cross validation, we can judge the accuarcy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.90 GiB for an array with shape (28587, 90, 120, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodeldir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m img_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m, scores[train], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, callbacks\u001b[38;5;241m=\u001b[39m[checkpoint], epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Grab Results\u001b[39;00m\n\u001b[0;32m     20\u001b[0m img_model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodeldir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.90 GiB for an array with shape (28587, 90, 120, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# Image Model\n",
    "kf = KFold(n_folds)\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "\n",
    "fold_var = 1\n",
    "for train, val in kf.split(images, scores):\n",
    "\t# Make image model for testing\n",
    "\timg_model = Model(inputs=img_input, outputs=img_output, name=\"img_model\")\n",
    "\timg_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "\t# Callback Saving\n",
    "\tcheckpoint = ModelCheckpoint(f\"{modeldir}/model_{fold_var}.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\t# Fit\n",
    "\thistory = img_model.fit(images[train], scores[train], callbacks=[checkpoint], epochs=epochs)\n",
    "\n",
    "\t# Grab Results\n",
    "\timg_model.load_weights(f\"{modeldir}/model_{fold_var}.h5\")\n",
    "\t\n",
    "\tresults = img_model.evaluate(images[val], scores[val])\n",
    "\tresults = dict(zip(img_model.metrics_names, results))\n",
    "\t\n",
    "\tvalidation_accuracy.append(results['accuracy'])\n",
    "\tvalidation_loss.append(results['loss'])\n",
    "\t\n",
    "\t# Clear\n",
    "\tclear_session()\n",
    "\n",
    "\t# Increment\n",
    "\tfold_var += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
