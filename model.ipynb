{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Machine Learning Model\n",
    "#### Created by Randhir and Andrew\n",
    "\n",
    "Model that will take a $90\\times120$ thumbnail JPEG and title from YouTube to output a video performance metric.\n",
    "The metric will be \n",
    "$$Score=\\log{(View\\ Count + 1)}$$\n",
    "The idea is that the video that attracted more views is a good video. The value is log-scaled as the higher the view count, the less meaningful it becomes. This value will be normalized with the maximum value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re, requests, os, json, random\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "from pathlib import Path\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_keras.backend import clear_session\n",
    "from tf_keras.callbacks import ModelCheckpoint\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Concatenate, TextVectorization, Input\n",
    "from tf_keras.preprocessing.text import Tokenizer\n",
    "from tf_keras.preprocessing.sequence import pad_sequences\n",
    "from tf_keras.utils import Sequence\n",
    "from tf_keras import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file with your api key\n",
    "if not load_dotenv():\n",
    "\tprint(\".env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "This cell contains the constants used by this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# File Structure\n",
    "dirpath = \"thumbnail\"\n",
    "modeldir = \"models\"\n",
    "datafile = \"data-filtered.csv\"\n",
    "\n",
    "# Data Aquisition\n",
    "filepath = \"data.csv\"\n",
    "count = 50\n",
    "max_iterations = 100 # 50 * 100 = 5000 videos\n",
    "topic_id = \"/m/03hf_rm\" # Strategy Games\n",
    "lang = \"en\"\n",
    "API_KEY = os.getenv(\"APIKEY\")\n",
    "\n",
    "# Data Filtering\n",
    "MULT_CSV = False\n",
    "filepath = \"data.csv\"\n",
    "filepath_2 = \"data_2.csv\"\n",
    "filepath_final = \"data-filtered.csv\"\n",
    "lang = \"en\"\n",
    "\n",
    "# Labeling\n",
    "MAX_VIEWS = 15.3e9 # Baby Shark Video (Most Viewed Video)\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# Vectorization\n",
    "vectorizator_model = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(vectorizator_model)\n",
    "transformer_model = TFAutoModel.from_pretrained(vectorizator_model)\n",
    "\n",
    "# Regex Patterns\n",
    "emoji_re = \"[\\U000000A9-\\U0010ffff]\"\n",
    "punc_re = f\"[{re.escape(string.punctuation)}]\"\n",
    "space_re = \"\\s{1,}\"\n",
    "\n",
    "# Download Stopwords & pattern\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "sw_re = f'\\b(?:{\"|\".join([f\"{re.escape(sw)}\" for sw in stopwords_list])})\\b'\n",
    "\n",
    "# Text Model Settings\n",
    "text_input_dim = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "# KFold Settings\n",
    "n_folds = 5\n",
    "epochs = 10\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Aquisition\n",
    "The YouTube API is used to get video data. This includes a video's thumbnail and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data file already exist\n",
    "if os.path.isfile(filepath):\n",
    "    df = pd.read_csv(filepath, index_col=\"yt-id\")\n",
    "else:\n",
    "    df = pd.DataFrame([], columns=[\"yt-id\", \"title\", \"created\", \"channel-id\", \"thumbnail\", \"thumbnail-w\", \"thumbnail-h\", \"view-count\", \"like-count\", \"comment-count\", \"query\"])\n",
    "    df = df.set_index(\"yt-id\")\n",
    "    \n",
    "# Grab missing data IDs for query\n",
    "yt_ids = list(df[df[\"view-count\"].isna()].index)\n",
    "\n",
    "# Loop\n",
    "yt_reads = 0\n",
    "for i in range(max_iterations):\n",
    "    try:\n",
    "        # Check if any stats calls are needed\n",
    "        if len(yt_ids) > 0:\n",
    "            # Message \n",
    "            print(\"Pulling statistics for missing data values\")\n",
    "\n",
    "            # Split up batch by 50 if needed\n",
    "            for index_split in range(50, len(yt_ids) + 1, 50):\n",
    "                # Generate & call statistic query (1 unit)\n",
    "                urlData_stats = f\"https://www.googleapis.com/youtube/v3/videos?key={API_KEY}&part=statistics&id={','.join(yt_ids[index_split - 50:index_split])}\"\n",
    "                webURL_stats = urllib.request.urlopen(urlData_stats)\n",
    "                raw_stats_data = webURL_stats.read()\n",
    "                results_stats = json.loads(raw_stats_data.decode(webURL_stats.info().get_content_charset('utf-8')))\n",
    "\n",
    "                # Process Stats Response\n",
    "                for stats_data in results_stats[\"items\"]:\n",
    "                    try:\n",
    "                        # Parse data\n",
    "                        new_row = pd.DataFrame([{\n",
    "                            \"yt-id\": stats_data['id'],\n",
    "                            \"view-count\": stats_data['statistics']['viewCount'],\n",
    "                            \"like-count\": stats_data['statistics']['likeCount'] if 'likeCount' in stats_data['statistics'] else \"\",\n",
    "                            \"comment-count\": stats_data['statistics']['commentCount'] if 'commentCount' in stats_data['statistics'] else \"\",\n",
    "                        },])\n",
    "                        new_row = new_row.set_index(\"yt-id\")\n",
    "\n",
    "                        # Update main dataset\n",
    "                        df.update(new_row)\n",
    "                    except KeyError:\n",
    "                        # Weird Entry\n",
    "                        continue\n",
    "\n",
    "            # Reset after used\n",
    "            yt_ids = [] \n",
    "\n",
    "            # Message \n",
    "            print(\"Finished pulling statistics for current batch\")\n",
    "\n",
    "        # Message\n",
    "        print(f\"Pulling {count} random videos\")\n",
    "\n",
    "        # Generates random query for YT\n",
    "        r_q = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(3))\n",
    "\n",
    "        # Calls the API for search results (100 units)\n",
    "        urlData_query = f\"https://www.googleapis.com/youtube/v3/search?key={API_KEY}&maxResults={count}&part=snippet&type=video&relevanceLanguage={lang}&topicId={topic_id}&q={r_q}\"\n",
    "        webURL_query = urllib.request.urlopen(urlData_query)\n",
    "        raw_vid_data = webURL_query.read()\n",
    "        results_vids = json.loads(raw_vid_data.decode(webURL_query.info().get_content_charset('utf-8')))\n",
    "\n",
    "        # Process Video Response\n",
    "        for video_data in results_vids['items']:\n",
    "            # Ignore Live and Upcoming Content (no ratings yet)\n",
    "            if video_data['snippet']['liveBroadcastContent'] != \"none\":\n",
    "                continue\n",
    "\n",
    "            # Parse data\n",
    "            try:\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"yt-id\": video_data['id']['videoId'],\n",
    "                    \"title\": video_data['snippet']['title'],\n",
    "                    \"created\": video_data['snippet']['publishedAt'],\n",
    "                    \"channel-id\": video_data['snippet']['channelId'],\n",
    "                    \"thumbnail\": video_data['snippet']['thumbnails'][\"default\"][\"url\"],\n",
    "                    \"thumbnail-w\": video_data['snippet']['thumbnails'][\"default\"][\"width\"],\n",
    "                    \"thumbnail-h\": video_data['snippet']['thumbnails'][\"default\"][\"height\"],\n",
    "                    \"query\": r_q,\n",
    "                },])\n",
    "                new_row = new_row.set_index(\"yt-id\")\n",
    "\n",
    "                try:\n",
    "                    # Append\n",
    "                    df = pd.concat([df, new_row], verify_integrity=True)\n",
    "\n",
    "                    # Store your ids\n",
    "                    yt_reads += 1\n",
    "\n",
    "                    # Prepare id for stats query\n",
    "                    yt_ids.append(video_data['id']['videoId'])\n",
    "                except ValueError:\n",
    "                    # Duplicate video detected\n",
    "                    continue\n",
    "            except KeyError:\n",
    "                # Weird Entry\n",
    "                continue\n",
    "\n",
    "        # Update User\n",
    "        print(f\"API call #{i + 1} successfully\")\n",
    "\n",
    "        # Dumb Data to prevent loss every 5 runs\n",
    "        if i % 5 == 0:\n",
    "            df.to_csv(filepath)\n",
    "\n",
    "    # ON API failure, quit and save\n",
    "    except urllib.error.HTTPError:\n",
    "        print(\"Latest API call failed. You are likely out of units. Try again tomorrow.\")\n",
    "        break\n",
    "    \n",
    "# Write to csv\n",
    "df.to_csv(filepath)\n",
    "\n",
    "# Termination\n",
    "print(f\"Was able to pull {yt_reads} rows\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After aquiring the data, the thumbnail images need to be pulled as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Filtering\n",
    "Some of the pulled data need to be filtered before usage. This includes potential duplicates and non english entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv(filepath, index_col=\"yt-id\")\n",
    "\n",
    "# Merge multiple if needed\n",
    "if MULT_CSV:\n",
    "\tdf_2 = pd.read_csv(filepath_2, index_col=\"yt-id\")\n",
    "\tdf = pd.concat([df, df_2])\n",
    "\n",
    "print(f\"{df.size} rows in data file\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "print(f\"{df.size} rows remaining after duplication filter\")\n",
    "\n",
    "# Remove non language\n",
    "def lang_filter(row) -> bool:\n",
    "\ttry:\n",
    "\t\tprint(row[\"title\"])\n",
    "\t\treturn detect(row[\"title\"]) == lang\n",
    "\texcept LangDetectException:\n",
    "\t\treturn False\n",
    "\t\n",
    "df = df[df.apply(lang_filter, axis=1)]\n",
    "print(f\"{df.size} rows remaining after translation filter\")\n",
    "\n",
    "# Save Filtered Data\n",
    "df.to_csv(filepath_final)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thumbnail Requesting\n",
    "Once the dataset has been filtered, the thumbnails can now be pulled. Images that do not fit the $90\\times120$ size will be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab data\n",
    "df = pd.read_csv(filepath, index_col=\"yt-id\")\n",
    "\n",
    "# Make directory for image if not already\n",
    "if not os.path.isdir(dirpath):\n",
    "\tos.mkdir(dirpath)\n",
    "\n",
    "# Iterate thru dataframe and download\n",
    "def grab_thumbnail(x : pd.Series):\n",
    "\t# Check if file exist\n",
    "\tfilename = f'{dirpath}/{x.name}.jpg'\n",
    "\tif os.path.isfile(filename):\n",
    "\t\tprint(f\"Thumbnail already retrieved for {x.name}\")\n",
    "\t\treturn\n",
    "\n",
    "\t# Call file\n",
    "\twith open(filename, 'wb') as handle:\n",
    "\t\tprint(f\"Retrieving thumbnail for {x.name}\")\n",
    "\t\tresponse = requests.get(x[\"thumbnail\"], stream=True)\n",
    "\n",
    "\t\t# Fail request\n",
    "\t\tif not response.ok:\n",
    "\t\t\tprint(f\"Could not retrieve thumbnail for {x.name}\")\n",
    "\n",
    "\t\t# Success save\n",
    "\t\tfor block in response.iter_content(1024):\n",
    "\t\t\tif not block:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\thandle.write(block)\n",
    "\n",
    "# Apply to all\n",
    "df.apply(grab_thumbnail, axis=1)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02v-CVttnS0.jpg deleted\n",
      "0EZUP5Vtemw.jpg deleted\n",
      "4KlB4i4dEWU.jpg deleted\n",
      "6JhUQpe-J6U.jpg deleted\n",
      "bAHQy0QFUMI.jpg deleted\n",
      "DcejDtVA4MU.jpg deleted\n",
      "E0Hchyxwr4c.jpg deleted\n",
      "ffLdLgSbpEc.jpg deleted\n",
      "hstJLLvhYSM.jpg deleted\n",
      "htE2M7shdfI.jpg deleted\n",
      "JTwsU2dDpEg.jpg deleted\n",
      "Lpnw6hMIu24.jpg deleted\n",
      "Q9D-aQzRuU4.jpg deleted\n",
      "RPoQZ_926hQ.jpg deleted\n",
      "Sl2ueV8kRRU.jpg deleted\n",
      "StkNJFSGksg.jpg deleted\n",
      "tnAYVF1-q74.jpg deleted\n",
      "VDg_U-n3t-I.jpg deleted\n",
      "X82cgnMGeD8.jpg deleted\n",
      "XO6KolPTH8U.jpg deleted\n",
      "XY6Iw4kTOEI.jpg deleted\n",
      "yQKNzY4HGGg.jpg deleted\n",
      "ZBbw3WfcxN8.jpg deleted\n"
     ]
    }
   ],
   "source": [
    "# Filter Images\n",
    "files = [f for f in os.listdir(dirpath) if os.path.isfile(f\"{dirpath}/{f}\") and f.endswith(\".jpg\")]\n",
    "image_ids = []\n",
    "i = 0\n",
    "for f in files:\n",
    "\tim = None\n",
    "\ttry:\n",
    "\t\tim = Image.open(f\"{dirpath}/{f}\")\n",
    "\n",
    "\t\tif im.size != (120, 90):\n",
    "\t\t\tim.close()\n",
    "\t\t\tPath.unlink(f\"{dirpath}/{f}\")\n",
    "\t\t\tprint(f\"{f} deleted\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tim.close()\n",
    "\t\tim = None\n",
    "\n",
    "\t\t# Save valid indexes for filtering\n",
    "\t\timage_ids.append(f[:-4])\n",
    "\texcept:\n",
    "\t\t# Close bad files\n",
    "\t\tif im is not None:\n",
    "\t\t\tim.close()\n",
    "\t\t\tim = None\n",
    "\n",
    "\t\t# Delete Bad Files\n",
    "\t\tPath.unlink(f\"{dirpath}/{f}\")\n",
    "\t\tprint(f\"{f} deleted\")\n",
    "\n",
    "\ti += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n",
    "This process involves text processing and image processing. This will involve text standardization and vectorization. For the image, it needs to be processed and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thumbnail-w</th>\n",
       "      <th>thumbnail-h</th>\n",
       "      <th>view-count</th>\n",
       "      <th>like-count</th>\n",
       "      <th>comment-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35734.0</td>\n",
       "      <td>35734.0</td>\n",
       "      <td>3.527600e+04</td>\n",
       "      <td>3.428900e+04</td>\n",
       "      <td>35006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.287259e+04</td>\n",
       "      <td>2.304083e+03</td>\n",
       "      <td>115.992858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.687911e+06</td>\n",
       "      <td>3.117386e+04</td>\n",
       "      <td>1640.940831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.815000e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.153250e+03</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.232996e+08</td>\n",
       "      <td>2.686147e+06</td>\n",
       "      <td>146332.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       thumbnail-w  thumbnail-h    view-count    like-count  comment-count\n",
       "count      35734.0      35734.0  3.527600e+04  3.428900e+04   35006.000000\n",
       "mean         120.0         90.0  9.287259e+04  2.304083e+03     115.992858\n",
       "std            0.0          0.0  1.687911e+06  3.117386e+04    1640.940831\n",
       "min          120.0         90.0  0.000000e+00  0.000000e+00       0.000000\n",
       "25%          120.0         90.0  3.000000e+01  1.000000e+00       0.000000\n",
       "50%          120.0         90.0  2.815000e+02  8.000000e+00       1.000000\n",
       "75%          120.0         90.0  3.153250e+03  7.500000e+01      12.000000\n",
       "max          120.0         90.0  2.232996e+08  2.686147e+06  146332.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(datafile, index_col=\"yt-id\")\n",
    "\n",
    "# Filter raw data for thumbnail only entries\n",
    "thumbnail_ids = np.array([f[:-4] for f in os.listdir(dirpath) if os.path.isfile(f\"{dirpath}/{f}\") and f.endswith(\".jpg\")], dtype=str)\n",
    "raw_data = raw_data.loc[thumbnail_ids]\n",
    "\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# Text Processing\n",
    "def text_standardization(raw_strs):\n",
    "\tt = tf.strings.lower(raw_strs)\n",
    "\tt = tf.strings.regex_replace(t, emoji_re, \"\")\n",
    "\tt = tf.strings.regex_replace(t, sw_re, \"\")\n",
    "\tt = tf.strings.regex_replace(t, punc_re, \"\")\n",
    "\tt = tf.strings.regex_replace(t, space_re, \" \")\n",
    "\treturn t\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer_layer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer_layer.fit_on_texts(raw_data[\"title\"])\n",
    "sequences = tokenizer_layer.texts_to_sequences(raw_data[\"title\"])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10, padding='post')\n",
    "\n",
    "# Input \n",
    "input_texts = tokenizer(list(raw_data[\"title\"]), padding=True, truncation=True, max_length=10, return_tensors=\"tf\")\n",
    "print(input_texts.keys())\n",
    "# input_texts.pop(\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(35734, 10), dtype=int32, numpy=\n",
       "array([[  101, 22159,  5886, ...,  3995,  5104,   102],\n",
       "       [  101, 25993,  1998, ...,  1010,  2208,   102],\n",
       "       [  101, 22563,  2099, ...,  2401,  1011,   102],\n",
       "       ...,\n",
       "       [  101,  2162,  8505, ...,  1027,  3704,   102],\n",
       "       [  101,   100,   100, ...,     0,     0,     0],\n",
       "       [  101, 14154, 11563, ...,  4684,  2112,   102]], dtype=int32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35734.000000\n",
       "mean         0.251066\n",
       "std          0.141486\n",
       "min          0.000000\n",
       "25%          0.142091\n",
       "50%          0.237930\n",
       "75%          0.341665\n",
       "max          0.819749\n",
       "Name: view-count, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Processing\n",
    "scores = raw_data[\"view-count\"] # Grab View Count\n",
    "scores = scores.fillna(0.0) # Replace NaN with 0\n",
    "scores = scores.map(lambda x : np.log10(x + 1)) # Log everything to make it less extreme\n",
    "scores = scores.div(np.log10(MAX_VIEWS + 1)) # Normalized (+1 to prevent one)\n",
    "\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35734.000000\n",
       "mean         0.158281\n",
       "std          0.365009\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: view-count, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean Label\n",
    "b_scores = scores.map(lambda x : int(x >= THRESHOLD))\n",
    "\n",
    "b_scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, the Sequential API is used to train a model. However, due to the need for more than one input, the Functional API must be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"img_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 90, 120, 3)]      0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 90, 120, 32)       2432      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 45, 60, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 45, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 22, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 30, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 11, 15, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21120)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               2703488   \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2806593 (10.71 MB)\n",
      "Trainable params: 2806593 (10.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Image Portion\n",
    "img_input = Input((90, 120, 3))\n",
    "x = Conv2D(32, 5, activation='relu', padding='same')(img_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x_out = Dropout(0.5)(x)\n",
    "x_out = Dense(64, activation='relu')(x_out)\n",
    "img_output = Dense(1, activation='sigmoid')(x_out)\n",
    "\n",
    "img_model = Model(inputs=img_input, outputs=img_output, name=\"img_model\")\n",
    "\n",
    "img_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text_inputs (InputLayer)    [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_masks (InputLaye  [(None, 10)]                 0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tf_bert_model_4 (TFBertMod  TFBaseModelOutputWithPooli   1094822   ['text_inputs[0][0]',         \n",
      " el)                         ngAndCrossAttentions(last_   40         'attention_masks[0][0]']     \n",
      "                             hidden_state=(None, 10, 76                                           \n",
      "                             8),                                                                  \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 768)                  0         ['tf_bert_model_4[0][0]']     \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  98432     ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    129       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109580801 (418.02 MB)\n",
      "Trainable params: 109580801 (418.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Text Portion\n",
    "text_input = Input(shape=(10,), dtype=tf.int32, name=\"text_inputs\")\n",
    "attention_mask = Input(shape=(10,), dtype=tf.int32, name=\"attention_masks\")\n",
    "\n",
    "transformer_output = transformer_model(text_input, attention_mask=attention_mask)\n",
    "y = transformer_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "y = Dense(128, activation='relu')(y)\n",
    "y_out = Dropout(0.5)(y)\n",
    "text_output = Dense(1, activation='sigmoid')(y_out)\n",
    "\n",
    "text_model = Model(inputs=[text_input, attention_mask], outputs=text_output, name=\"text_model\")\n",
    "\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unitied_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 90, 120, 3)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 90, 120, 32)          2432      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 45, 60, 32)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 45, 60, 64)           18496     ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 22, 30, 64)           0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 22, 30, 128)          73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 11, 15, 128)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertMod  TFBaseModelOutputWithPooli   1094822   ['input_3[0][0]',             \n",
      " el)                         ngAndCrossAttentions(last_   40         'input_4[0][0]']             \n",
      "                             hidden_state=(None, 10, 76                                           \n",
      "                             8),                                                                  \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 21120)                0         ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 768)                  0         ['tf_bert_model_1[0][0]']     \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  2703488   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 128)                  98432     ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 256)                  0         ['dense_3[0][0]',             \n",
      " )                                                                   'dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)        (None, 256)                  0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 64)                   16448     ['dropout_77[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    65        ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 112395457 (428.75 MB)\n",
      "Trainable params: 112395457 (428.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# United Model\n",
    "z = Concatenate()([x, y])\n",
    "z = Dropout(0.5)(z)\n",
    "z = Dense(64, activation='relu')(z)\n",
    "z = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "united_model = Model(inputs=[img_input, text_input, attention_mask], outputs=z, name=\"unitied_model\")\n",
    "\n",
    "united_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Using k-fold cross validation, we can judge the accuarcy of this model. To start, we need to make a generator class to batch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailDataGenerator(Sequence):\n",
    "\n",
    "\tdef __init__(self, filedir : str, list_IDs : list[str], labels : dict[str, float], rescale : float=255.0, filetype : str=\"jpg\", batch_size : int=32, dim : tuple[int, int]=(90, 120), shuffle=True, **kwargs):\n",
    "\t\t'''\n",
    "\t\tData Generator Initialization Function \n",
    "\t\t'''\n",
    "\t\tself.filedir = filedir\n",
    "\t\tself.filetype = filetype\n",
    "\t\tself.dim = dim\n",
    "\t\tself.rescale = rescale\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.labels = labels\n",
    "\t\tself.list_IDs = list_IDs\n",
    "\t\tself.shuffle = shuffle\n",
    "\t\tself.on_epoch_end()\n",
    "\n",
    "\tdef on_epoch_end(self):\n",
    "\t\t'''\n",
    "\t\tUpdates indexes after each epoch\n",
    "\t\t'''\n",
    "\t\tself.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "\t\t# Randomize if Shuffle\n",
    "\t\tif self.shuffle:\n",
    "\t\t\tnp.random.shuffle(self.indexes)\n",
    "\n",
    "\tdef __data_generation(self, list_IDs_temp):\n",
    "\t\t'''\n",
    "\t\tGenerates data containing batch_size samples\n",
    "\t\t'''\n",
    "\t\t# Initialization\n",
    "\t\tX = np.empty((self.batch_size, *self.dim, 3))\n",
    "\t\ty = np.empty((self.batch_size), dtype=float)\n",
    "\n",
    "\t\t# Generate data\n",
    "\t\tfor i, ID in enumerate(list_IDs_temp):\n",
    "\t\t\t# Store sample\n",
    "\t\t\tX[i,] = Image.open(f'{self.filedir}/{ID}.{self.filetype}')\n",
    "\n",
    "\t\t\t# Store class\n",
    "\t\t\ty[i] = self.labels[ID]\n",
    "\n",
    "\t\t# Rescale\n",
    "\t\tX /= self.rescale\n",
    "\n",
    "\t\treturn X, y\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\t'''\n",
    "\t\tDenotes the number of batches per epoch\n",
    "\t\t'''\n",
    "\t\treturn int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t'''\n",
    "\t\tGenerate one batch of data\n",
    "\t\t'''\n",
    "\t\t# Generate indexes of the batch\n",
    "\t\tindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "\t\t# Find list of IDs\n",
    "\t\tlist_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "\t\t# Generate data\n",
    "\t\treturn self.__data_generation(list_IDs_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image-only model will undergo a k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting k-Fold #1\n",
      "Epoch 1/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9153 - precision: 0.8144 - recall: 0.6247\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85532, saving model to models\\model_1.keras\n",
      "952/952 [==============================] - 261s 273ms/step - loss: 0.2164 - accuracy: 0.9153 - precision: 0.8144 - recall: 0.6247 - val_loss: 0.4142 - val_accuracy: 0.8553 - val_precision: 0.4575 - val_recall: 0.2908\n",
      "Epoch 2/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9246 - precision: 0.8171 - recall: 0.6939\n",
      "Epoch 2: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1887 - accuracy: 0.9246 - precision: 0.8171 - recall: 0.6939 - val_loss: 0.4615 - val_accuracy: 0.8521 - val_precision: 0.4412 - val_recall: 0.2908\n",
      "Epoch 3/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9335 - precision: 0.8378 - recall: 0.7351\n",
      "Epoch 3: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1711 - accuracy: 0.9335 - precision: 0.8378 - recall: 0.7351 - val_loss: 0.4848 - val_accuracy: 0.8388 - val_precision: 0.4066 - val_recall: 0.3772\n",
      "Epoch 4/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9377 - precision: 0.8406 - recall: 0.7641\n",
      "Epoch 4: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1571 - accuracy: 0.9377 - precision: 0.8406 - recall: 0.7641 - val_loss: 0.5164 - val_accuracy: 0.8472 - val_precision: 0.4173 - val_recall: 0.2857\n",
      "Epoch 5/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9457 - precision: 0.8612 - recall: 0.7959\n",
      "Epoch 5: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1402 - accuracy: 0.9457 - precision: 0.8612 - recall: 0.7959 - val_loss: 0.5207 - val_accuracy: 0.8340 - val_precision: 0.3764 - val_recall: 0.3147\n",
      "Epoch 6/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9503 - precision: 0.8703 - recall: 0.8178\n",
      "Epoch 6: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1296 - accuracy: 0.9503 - precision: 0.8703 - recall: 0.8178 - val_loss: 0.5782 - val_accuracy: 0.8436 - val_precision: 0.4068 - val_recall: 0.3075\n",
      "Epoch 7/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9534 - precision: 0.8708 - recall: 0.8396\n",
      "Epoch 7: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 97s 102ms/step - loss: 0.1198 - accuracy: 0.9534 - precision: 0.8708 - recall: 0.8396 - val_loss: 0.6704 - val_accuracy: 0.8518 - val_precision: 0.4412 - val_recall: 0.2946\n",
      "Epoch 8/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9585 - precision: 0.8845 - recall: 0.8587\n",
      "Epoch 8: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.1093 - accuracy: 0.9585 - precision: 0.8845 - recall: 0.8587 - val_loss: 0.6285 - val_accuracy: 0.8415 - val_precision: 0.4128 - val_recall: 0.3673\n",
      "Epoch 9/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9598 - precision: 0.8878 - recall: 0.8631\n",
      "Epoch 9: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.1054 - accuracy: 0.9598 - precision: 0.8878 - recall: 0.8631 - val_loss: 0.6708 - val_accuracy: 0.8499 - val_precision: 0.4328 - val_recall: 0.2953\n",
      "Epoch 10/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9618 - precision: 0.8935 - recall: 0.8700\n",
      "Epoch 10: val_accuracy did not improve from 0.85532\n",
      "952/952 [==============================] - 97s 102ms/step - loss: 0.0982 - accuracy: 0.9618 - precision: 0.8935 - recall: 0.8700 - val_loss: 0.7037 - val_accuracy: 0.8438 - val_precision: 0.4031 - val_recall: 0.2914\n",
      "238/238 [==============================] - 8s 32ms/step - loss: 0.3515 - accuracy: 0.8686 - precision: 0.5599 - recall: 0.2049\n",
      "Starting k-Fold #2\n",
      "Epoch 1/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.8557 - precision: 0.6234 - recall: 0.1857\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85980, saving model to models\\model_2.keras\n",
      "952/952 [==============================] - 175s 182ms/step - loss: 0.3457 - accuracy: 0.8557 - precision: 0.6234 - recall: 0.1857 - val_loss: 0.3351 - val_accuracy: 0.8598 - val_precision: 0.7104 - val_recall: 0.2835\n",
      "Epoch 2/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8610 - precision: 0.6579 - recall: 0.2256\n",
      "Epoch 2: val_accuracy improved from 0.85980 to 0.85994, saving model to models\\model_2.keras\n",
      "952/952 [==============================] - 177s 186ms/step - loss: 0.3312 - accuracy: 0.8610 - precision: 0.6579 - recall: 0.2256 - val_loss: 0.3325 - val_accuracy: 0.8599 - val_precision: 0.7251 - val_recall: 0.2718\n",
      "Epoch 3/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8668 - precision: 0.6500 - recall: 0.3145\n",
      "Epoch 3: val_accuracy did not improve from 0.85994\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.3155 - accuracy: 0.8668 - precision: 0.6500 - recall: 0.3145 - val_loss: 0.3352 - val_accuracy: 0.8576 - val_precision: 0.7527 - val_recall: 0.2303\n",
      "Epoch 4/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.8774 - precision: 0.6787 - recall: 0.4041\n",
      "Epoch 4: val_accuracy did not improve from 0.85994\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2949 - accuracy: 0.8774 - precision: 0.6787 - recall: 0.4041 - val_loss: 0.3470 - val_accuracy: 0.8577 - val_precision: 0.7173 - val_recall: 0.2554\n",
      "Epoch 5/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.8847 - precision: 0.6873 - recall: 0.4775\n",
      "Epoch 5: val_accuracy improved from 0.85994 to 0.86289, saving model to models\\model_2.keras\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2734 - accuracy: 0.8847 - precision: 0.6873 - recall: 0.4775 - val_loss: 0.3350 - val_accuracy: 0.8629 - val_precision: 0.6862 - val_recall: 0.3405\n",
      "Epoch 6/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.8953 - precision: 0.7140 - recall: 0.5471\n",
      "Epoch 6: val_accuracy did not improve from 0.86289\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2528 - accuracy: 0.8953 - precision: 0.7140 - recall: 0.5471 - val_loss: 0.3385 - val_accuracy: 0.8599 - val_precision: 0.6416 - val_recall: 0.3824\n",
      "Epoch 7/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9035 - precision: 0.7274 - recall: 0.6092\n",
      "Epoch 7: val_accuracy did not improve from 0.86289\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2293 - accuracy: 0.9035 - precision: 0.7274 - recall: 0.6092 - val_loss: 0.3479 - val_accuracy: 0.8510 - val_precision: 0.5812 - val_recall: 0.4110\n",
      "Epoch 8/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9126 - precision: 0.7494 - recall: 0.6592\n",
      "Epoch 8: val_accuracy did not improve from 0.86289\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2114 - accuracy: 0.9126 - precision: 0.7494 - recall: 0.6592 - val_loss: 0.3844 - val_accuracy: 0.8546 - val_precision: 0.6211 - val_recall: 0.3480\n",
      "Epoch 9/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9183 - precision: 0.7580 - recall: 0.6985\n",
      "Epoch 9: val_accuracy did not improve from 0.86289\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1970 - accuracy: 0.9183 - precision: 0.7580 - recall: 0.6985 - val_loss: 0.3641 - val_accuracy: 0.8513 - val_precision: 0.5805 - val_recall: 0.4201\n",
      "Epoch 10/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9261 - precision: 0.7831 - recall: 0.7260\n",
      "Epoch 10: val_accuracy did not improve from 0.86289\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1801 - accuracy: 0.9261 - precision: 0.7831 - recall: 0.7260 - val_loss: 0.3827 - val_accuracy: 0.8476 - val_precision: 0.5553 - val_recall: 0.4608\n",
      "238/238 [==============================] - 8s 32ms/step - loss: 0.3310 - accuracy: 0.8609 - precision: 0.6923 - recall: 0.3142\n",
      "Starting k-Fold #3\n",
      "Epoch 1/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.8714 - precision: 0.6787 - recall: 0.3380\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88543, saving model to models\\model_3.keras\n",
      "952/952 [==============================] - 100s 104ms/step - loss: 0.3105 - accuracy: 0.8714 - precision: 0.6787 - recall: 0.3380 - val_loss: 0.2947 - val_accuracy: 0.8854 - val_precision: 0.7553 - val_recall: 0.4529\n",
      "Epoch 2/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.8764 - precision: 0.6775 - recall: 0.4017\n",
      "Epoch 2: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2927 - accuracy: 0.8764 - precision: 0.6775 - recall: 0.4017 - val_loss: 0.2976 - val_accuracy: 0.8739 - val_precision: 0.7789 - val_recall: 0.3314\n",
      "Epoch 3/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.8846 - precision: 0.6880 - recall: 0.4786\n",
      "Epoch 3: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2760 - accuracy: 0.8846 - precision: 0.6880 - recall: 0.4786 - val_loss: 0.3008 - val_accuracy: 0.8730 - val_precision: 0.7605 - val_recall: 0.3387\n",
      "Epoch 4/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.8919 - precision: 0.7046 - recall: 0.5331\n",
      "Epoch 4: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2564 - accuracy: 0.8919 - precision: 0.7046 - recall: 0.5331 - val_loss: 0.2949 - val_accuracy: 0.8789 - val_precision: 0.6989 - val_recall: 0.4712\n",
      "Epoch 5/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9022 - precision: 0.7259 - recall: 0.6027\n",
      "Epoch 5: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 102ms/step - loss: 0.2337 - accuracy: 0.9022 - precision: 0.7259 - recall: 0.6027 - val_loss: 0.2968 - val_accuracy: 0.8770 - val_precision: 0.6975 - val_recall: 0.4530\n",
      "Epoch 6/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9098 - precision: 0.7455 - recall: 0.6433\n",
      "Epoch 6: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2176 - accuracy: 0.9098 - precision: 0.7455 - recall: 0.6433 - val_loss: 0.3069 - val_accuracy: 0.8717 - val_precision: 0.6465 - val_recall: 0.4966\n",
      "Epoch 7/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9169 - precision: 0.7596 - recall: 0.6860\n",
      "Epoch 7: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1991 - accuracy: 0.9169 - precision: 0.7596 - recall: 0.6860 - val_loss: 0.3335 - val_accuracy: 0.8741 - val_precision: 0.7228 - val_recall: 0.3883\n",
      "Epoch 8/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9253 - precision: 0.7848 - recall: 0.7207\n",
      "Epoch 8: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1810 - accuracy: 0.9253 - precision: 0.7848 - recall: 0.7207 - val_loss: 0.3291 - val_accuracy: 0.8675 - val_precision: 0.6321 - val_recall: 0.4793\n",
      "Epoch 9/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9285 - precision: 0.7855 - recall: 0.7475\n",
      "Epoch 9: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 102ms/step - loss: 0.1733 - accuracy: 0.9285 - precision: 0.7855 - recall: 0.7475 - val_loss: 0.3441 - val_accuracy: 0.8650 - val_precision: 0.6450 - val_recall: 0.4117\n",
      "Epoch 10/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9368 - precision: 0.8107 - recall: 0.7777\n",
      "Epoch 10: val_accuracy did not improve from 0.88543\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1542 - accuracy: 0.9368 - precision: 0.8107 - recall: 0.7777 - val_loss: 0.3826 - val_accuracy: 0.8634 - val_precision: 0.6630 - val_recall: 0.3548\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.2953 - accuracy: 0.8864 - precision: 0.7416 - recall: 0.4827\n",
      "Starting k-Fold #4\n",
      "Epoch 1/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8752 - precision: 0.6739 - recall: 0.3998\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88627, saving model to models\\model_4.keras\n",
      "952/952 [==============================] - 100s 104ms/step - loss: 0.3035 - accuracy: 0.8752 - precision: 0.6739 - recall: 0.3998 - val_loss: 0.2950 - val_accuracy: 0.8863 - val_precision: 0.8082 - val_recall: 0.3926\n",
      "Epoch 2/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.8822 - precision: 0.6923 - recall: 0.4522\n",
      "Epoch 2: val_accuracy did not improve from 0.88627\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2842 - accuracy: 0.8822 - precision: 0.6923 - recall: 0.4522 - val_loss: 0.2830 - val_accuracy: 0.8793 - val_precision: 0.8153 - val_recall: 0.3313\n",
      "Epoch 3/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.8898 - precision: 0.7010 - recall: 0.5228\n",
      "Epoch 3: val_accuracy improved from 0.88627 to 0.88950, saving model to models\\model_4.keras\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.2667 - accuracy: 0.8898 - precision: 0.7010 - recall: 0.5228 - val_loss: 0.2747 - val_accuracy: 0.8895 - val_precision: 0.7867 - val_recall: 0.4388\n",
      "Epoch 4/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.8994 - precision: 0.7292 - recall: 0.5731\n",
      "Epoch 4: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2459 - accuracy: 0.8994 - precision: 0.7292 - recall: 0.5731 - val_loss: 0.2709 - val_accuracy: 0.8857 - val_precision: 0.7141 - val_recall: 0.4935\n",
      "Epoch 5/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9039 - precision: 0.7307 - recall: 0.6162\n",
      "Epoch 5: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.2306 - accuracy: 0.9039 - precision: 0.7307 - recall: 0.6162 - val_loss: 0.2792 - val_accuracy: 0.8874 - val_precision: 0.7131 - val_recall: 0.5125\n",
      "Epoch 6/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9134 - precision: 0.7540 - recall: 0.6676\n",
      "Epoch 6: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.2089 - accuracy: 0.9134 - precision: 0.7540 - recall: 0.6676 - val_loss: 0.2986 - val_accuracy: 0.8700 - val_precision: 0.6189 - val_recall: 0.5186\n",
      "Epoch 7/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9207 - precision: 0.7750 - recall: 0.6981\n",
      "Epoch 7: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1919 - accuracy: 0.9207 - precision: 0.7750 - recall: 0.6981 - val_loss: 0.2931 - val_accuracy: 0.8775 - val_precision: 0.6462 - val_recall: 0.5431\n",
      "Epoch 8/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9286 - precision: 0.7974 - recall: 0.7323\n",
      "Epoch 8: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1763 - accuracy: 0.9286 - precision: 0.7974 - recall: 0.7323 - val_loss: 0.3028 - val_accuracy: 0.8773 - val_precision: 0.6910 - val_recall: 0.4418\n",
      "Epoch 9/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9305 - precision: 0.8028 - recall: 0.7403\n",
      "Epoch 9: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.1714 - accuracy: 0.9305 - precision: 0.8028 - recall: 0.7403 - val_loss: 0.3308 - val_accuracy: 0.8702 - val_precision: 0.6406 - val_recall: 0.4529\n",
      "Epoch 10/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9369 - precision: 0.8106 - recall: 0.7810\n",
      "Epoch 10: val_accuracy did not improve from 0.88950\n",
      "952/952 [==============================] - 99s 104ms/step - loss: 0.1537 - accuracy: 0.9369 - precision: 0.8106 - recall: 0.7810 - val_loss: 0.3767 - val_accuracy: 0.8693 - val_precision: 0.7049 - val_recall: 0.3342\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.2762 - accuracy: 0.8895 - precision: 0.7789 - recall: 0.4466\n",
      "Starting k-Fold #5\n",
      "Epoch 1/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.8767 - precision: 0.6799 - recall: 0.4192\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89790, saving model to models\\model_5.keras\n",
      "952/952 [==============================] - 100s 104ms/step - loss: 0.2969 - accuracy: 0.8767 - precision: 0.6799 - recall: 0.4192 - val_loss: 0.2523 - val_accuracy: 0.8979 - val_precision: 0.8399 - val_recall: 0.4371\n",
      "Epoch 2/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.8836 - precision: 0.6909 - recall: 0.4810\n",
      "Epoch 2: val_accuracy did not improve from 0.89790\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2794 - accuracy: 0.8836 - precision: 0.6909 - recall: 0.4810 - val_loss: 0.2535 - val_accuracy: 0.8947 - val_precision: 0.8443 - val_recall: 0.4087\n",
      "Epoch 3/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.8944 - precision: 0.7153 - recall: 0.5527\n",
      "Epoch 3: val_accuracy improved from 0.89790 to 0.89860, saving model to models\\model_5.keras\n",
      "952/952 [==============================] - 100s 105ms/step - loss: 0.2577 - accuracy: 0.8944 - precision: 0.7153 - recall: 0.5527 - val_loss: 0.2653 - val_accuracy: 0.8986 - val_precision: 0.7922 - val_recall: 0.4840\n",
      "Epoch 4/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9014 - precision: 0.7347 - recall: 0.5906\n",
      "Epoch 4: val_accuracy improved from 0.89860 to 0.89930, saving model to models\\model_5.keras\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2384 - accuracy: 0.9014 - precision: 0.7347 - recall: 0.5906 - val_loss: 0.2493 - val_accuracy: 0.8993 - val_precision: 0.7957 - val_recall: 0.4871\n",
      "Epoch 5/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9082 - precision: 0.7513 - recall: 0.6293\n",
      "Epoch 5: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.2214 - accuracy: 0.9082 - precision: 0.7513 - recall: 0.6293 - val_loss: 0.2563 - val_accuracy: 0.8944 - val_precision: 0.7470 - val_recall: 0.5004\n",
      "Epoch 6/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9165 - precision: 0.7716 - recall: 0.6709\n",
      "Epoch 6: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 101s 106ms/step - loss: 0.2041 - accuracy: 0.9165 - precision: 0.7716 - recall: 0.6709 - val_loss: 0.2692 - val_accuracy: 0.8895 - val_precision: 0.7868 - val_recall: 0.4122\n",
      "Epoch 7/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9235 - precision: 0.7884 - recall: 0.7072\n",
      "Epoch 7: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 96s 101ms/step - loss: 0.1873 - accuracy: 0.9235 - precision: 0.7884 - recall: 0.7072 - val_loss: 0.2691 - val_accuracy: 0.8947 - val_precision: 0.7246 - val_recall: 0.5368\n",
      "Epoch 8/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9286 - precision: 0.8009 - recall: 0.7311\n",
      "Epoch 8: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 97s 102ms/step - loss: 0.1745 - accuracy: 0.9286 - precision: 0.8009 - recall: 0.7311 - val_loss: 0.2700 - val_accuracy: 0.8887 - val_precision: 0.6805 - val_recall: 0.5529\n",
      "Epoch 9/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9327 - precision: 0.8043 - recall: 0.7603\n",
      "Epoch 9: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 98s 103ms/step - loss: 0.1643 - accuracy: 0.9327 - precision: 0.8043 - recall: 0.7603 - val_loss: 0.3016 - val_accuracy: 0.8845 - val_precision: 0.6772 - val_recall: 0.5120\n",
      "Epoch 10/10\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9366 - precision: 0.8113 - recall: 0.7812\n",
      "Epoch 10: val_accuracy did not improve from 0.89930\n",
      "952/952 [==============================] - 99s 103ms/step - loss: 0.1540 - accuracy: 0.9366 - precision: 0.8113 - recall: 0.7812 - val_loss: 0.3188 - val_accuracy: 0.8833 - val_precision: 0.7088 - val_recall: 0.4428\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.2407 - accuracy: 0.9060 - precision: 0.8081 - recall: 0.5306\n"
     ]
    }
   ],
   "source": [
    "# Image Model\n",
    "kf = KFold(n_folds)\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "\n",
    "fold_var = 1\n",
    "for train, val in kf.split(thumbnail_ids, b_scores):\n",
    "\t# Fold Indicator\n",
    "\tprint(f\"Starting k-Fold #{fold_var}\")\n",
    "\n",
    "\t# Make image model for testing\n",
    "\timg_model = Model(inputs=img_input, outputs=img_output, name=\"img_model\")\n",
    "\timg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "\t# Callback Saving\n",
    "\tcheckpoint = ModelCheckpoint(f\"{modeldir}/model_{fold_var}.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\t# Generator\n",
    "\ttbdg_train = ThumbnailDataGenerator(dirpath, thumbnail_ids[train], b_scores.iloc[train], batch_size=batch_size)\n",
    "\ttbdg_validate = ThumbnailDataGenerator(dirpath, thumbnail_ids[val], b_scores.iloc[val], batch_size=batch_size)\n",
    "\n",
    "\t# Fit\n",
    "\thistory = img_model.fit(x=tbdg_train, validation_data=tbdg_validate, callbacks=[checkpoint], epochs=epochs)\n",
    "\n",
    "\t# Grab Results\n",
    "\timg_model.load_weights(f\"{modeldir}/model_{fold_var}.h5\")\n",
    "\t\n",
    "\tresults = img_model.evaluate(x=tbdg_validate)\n",
    "\tresults = dict(zip(img_model.metrics_names, results))\n",
    "\t\n",
    "\tvalidation_accuracy.append(results['accuracy'])\n",
    "\tvalidation_loss.append(results['loss'])\n",
    "\t\n",
    "\t# Clear\n",
    "\tclear_session()\n",
    "\n",
    "\t# Increment\n",
    "\tfold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text only model will undergo the same test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Image Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m kf \u001b[38;5;241m=\u001b[39m \u001b[43mKFold\u001b[49m(n_folds)\n\u001b[0;32m      4\u001b[0m validation_accuracy \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m validation_loss \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "# Image Model\n",
    "kf = KFold(n_folds)\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "\n",
    "fold_var = 1\n",
    "for train, val in kf.split(input_texts[\"input_ids\"], b_scores):\n",
    "\t# Fold Indicator\n",
    "\tprint(f\"Starting k-Fold #{fold_var}\")\n",
    "\n",
    "\t# Make image model for testing\n",
    "\ttext_model = Model(inputs=[text_input, attention_mask], outputs=text_output, name=\"text_model\")\n",
    "\ttext_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "\t# Callback Saving\n",
    "\tcheckpoint = ModelCheckpoint(f\"{modeldir}/model_{fold_var}.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\t# Train / Validation\n",
    "\ttrainset = {\n",
    "\t\t\"text_inputs\": tf.gather(input_texts[\"input_ids\"], indices=train), \n",
    "\t\t\"attention_masks\": tf.gather(input_texts[\"attention_mask\"], indices=train)\n",
    "\t}\n",
    "\ttestset = {\n",
    "\t\t\"text_inputs\": tf.gather(input_texts[\"input_ids\"], indices=val), \n",
    "\t\t\"attention_masks\": tf.gather(input_texts[\"attention_mask\"], indices=val)\n",
    "\t}\n",
    "\n",
    "\t# Fit\n",
    "\thistory = text_model.fit(x=trainset, y=b_scores.iloc[train], validation_data=(testset, b_scores.iloc[val]), callbacks=[checkpoint], epochs=epochs)\n",
    "\n",
    "\t# Grab Results\n",
    "\ttext_model.load_weights(f\"{modeldir}/model_{fold_var}.h5\")\n",
    "\t\n",
    "\tresults = text_model.evaluate(x=testset, y=b_scores.iloc[val])\n",
    "\tresults = dict(zip(text_model.metrics_names, results))\n",
    "\t\n",
    "\tvalidation_accuracy.append(results['accuracy'])\n",
    "\tvalidation_loss.append(results['loss'])\n",
    "\t\n",
    "\t# Clear\n",
    "\tclear_session()\n",
    "\n",
    "\t# Increment\n",
    "\tfold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "Once the k-fold cross validation is complete, the final model can be trained with all the data and can be tested with complete new data from the API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
